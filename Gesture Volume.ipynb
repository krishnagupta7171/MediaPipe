{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddee1612-38ff-4d7e-9920-711cb03fe3ee",
   "metadata": {},
   "source": [
    "# Gesture Volume Control"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a3b1fd9-4e9a-4915-b5fb-f3ddd14592f3",
   "metadata": {},
   "source": [
    "for this we need to install a Python library that lets us control our system's audio.\n",
    "It acts like a bridge between Python and the Windows Core Audio API.\n",
    "\n",
    "\n",
    "üîç What\t                  üìñ Meaning\n",
    "PyCAW\t                      Python library for Windows audio control\n",
    "Used for\t                  Getting and setting system volume\n",
    "Needed because             \t  MediaPipe only tracks gestures ‚Äî you need another way to control system audio\n",
    "Platform\t                  Windows-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b14c4172-ac8a-49f2-94c8-9afc6f6e1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import math\n",
    "\n",
    "# Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "mute_icon = cv2.imread(\"mute.png\", cv2.IMREAD_COLOR)\n",
    "icon_resized = cv2.resize(mute_icon, (50, 50))\n",
    "x_offset, y_offset = 50, 80   # Define where to place it\n",
    "# MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Get system volume interface\n",
    "devices = AudioUtilities.GetSpeakers() #This gets the default speaker device on your system.\n",
    "#It's the audio device your system is currently using for output (like your speakers or headphones).\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None) #This activates the volume interface for that audio device.\n",
    "#IAudioEndpointVolume._iid_: Tells the system which specific interface you want ‚Äî in this case, the one for controlling volume.\n",
    "#CLSCTX_ALL: Says to activate the interface in any context (in-process or out-of-process).\n",
    "#None: No extra data is passed when activating.\n",
    "volume_control = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "#here you're telling Python (through the ctypes library) to treat the generic interface object as a pointer to the\n",
    "#very specific IAudioEndpointVolume interface.\n",
    "#cast function, take this general pointer (interface) and reinterpret it as a pointer that specifically knows how to \n",
    "#interact with IAudioEndpointVolume objects.\n",
    "# Get volume range\n",
    "vol_min, vol_max = volume_control.GetVolumeRange()[:2] # This function will helps us to find the min and the \n",
    "# max value and the volumne step size. These all values will determined by our hardware system\n",
    "#[:2]\n",
    "#This is Python slicing.\n",
    "#It means: take only the first two values from the returned tuple.\n",
    "#So from (-65.25, 0.0, 0.03125) ‚Üí you get (-65.25, 0.0)\n",
    "min_ratio = 0.3\n",
    "max_ratio = 0.9\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(img_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            lm_list = []\n",
    "            h, w, c = img.shape\n",
    "            for id, lm in enumerate(hand_landmarks.landmark):\n",
    "                lm_list.append((int(lm.x * w), int(lm.y * h)))\n",
    "\n",
    "            # Get Thumb tip (id=4) and Index tip (id=8)\n",
    "            x0, y0 = lm_list[0]  # Wrist\n",
    "            x5, y5 = lm_list[5]  # Index base (MCP)\n",
    "            x1, y1 = lm_list[4]\n",
    "            x2, y2 = lm_list[8]\n",
    "\n",
    "            # Draw circles and line\n",
    "            cv2.circle(img, (x1, y1), 10, (255, 0, 0), cv2.FILLED)\n",
    "            cv2.circle(img, (x2, y2), 10, (255, 0, 0), cv2.FILLED)\n",
    "            #cv2.line(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate distance\n",
    "            hand_size_ref = math.hypot(x5 - x0, y5 - y0)\n",
    "            distance = math.hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "            if hand_size_ref != 0:\n",
    "                ratio = distance / hand_size_ref\n",
    "                cv2.putText(img, f\"Ratio: {ratio:.2f}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                # mute gesture\n",
    "                if distance < 55:\n",
    "                    volume_control.SetMasterVolumeLevel(vol_min, None)\n",
    "                    img[y_offset:y_offset+icon_resized.shape[0], x_offset:x_offset+icon_resized.shape[1]] = icon_resized\n",
    "            # Map distance to volume range\n",
    "                else:\n",
    "                    vol = np.interp(ratio, [min_ratio,max_ratio], [vol_min, vol_max])\n",
    "                    volume_control.SetMasterVolumeLevel(vol, None)\n",
    "                    #this line then sets the system's master volume to the calculated vol level.\n",
    "\n",
    "            # Draw volume bar\n",
    "                    vol_bar = np.interp(ratio, [min_ratio,max_ratio], [400, 150])\n",
    "                    cv2.rectangle(img, (50, 150), (85, 400), (0, 255, 0), 3)\n",
    "                    cv2.rectangle(img, (50, int(vol_bar)), (85, 400), (0, 255, 0), cv2.FILLED)\n",
    "\n",
    "            # Draw distance text\n",
    "                    cv2.putText(img, f'{int(distance)}', (50, 450),cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "                    mp_draw.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    cv2.imshow(\"Volume Control\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9872a47f-9f8e-4cbe-b2c1-a2af62288082",
   "metadata": {},
   "source": [
    "cv2 ‚Üí Webcam handling and drawing.\n",
    "mediapipe ‚Üí Hand landmark detection.\n",
    "numpy ‚Üí For interpolation (np.interp()).\n",
    "pycaw ‚Üí To control Windows system volume.\n",
    "math ‚Üí For distance calculation.\n",
    "\n",
    "ctypes: This Python library allows your code to work with low-level data types and functions found in libraries (like those that manage audio in Windows).\n",
    "\n",
    "cast: When your program gets information about the audio device, it might receive it in a generic format. cast is used to specifically tell Python to treat this information as a pointer to a particular type of object ‚Äì in this case, the IAudioEndpointVolume interface. It's like saying, \"Hey Python, I know this is a general pointer, but I want you to see it as a pointer that knows how to control volume. In short and simple Exactly! cast helps convert a general pointer (which might not have a defined structure) into a specific type of pointer associated with a particular task\n",
    "\n",
    "POINTER - A pointer is like a signpost in memory‚Äîit tells your program where to find a specific piece of data or an object.\n",
    "In this context, you need to define a pointer type that specifically points to the IAudioEndpointVolume interface, which allows your program to control audio settings like volume. By setting up this pointer, your program knows exactly where to look to access and modify the volume settings.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb36b8cc-7233-47c5-b6b4-bd4fe1ac0807",
   "metadata": {},
   "source": [
    "comtypes: This library helps Python work with COM objects. COM is how different software components in Windows can communicate with each other. Serves as a bridge between both.\n",
    "\n",
    "CLSCTX_ALL: When your program asks the system for the audio control interface, it needs to specify the context in which that interface might be running. CLSCTX_ALL tells the system to look for the audio control interface in all possible contexts, ensuring it can be found regardless of how it's currently running. \n",
    "This ultimately helps bridge the gap between Python and Windows' COM-based audio functionalities, enabling your program to control music and sound systems effectively."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4506f4d2-1935-4acb-8d11-f9c27cecb3fd",
   "metadata": {},
   "source": [
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "\n",
    "Certainly! The pycaw library is designed to simplify audio system interactions in Python by building upon foundational libraries like ctypes and comtypes. Let me break this down further:\n",
    "1. AudioUtilities:\n",
    "This module within pycaw provides functionality for discovering and managing audio endpoint devices. Endpoint devices refer to input/output devices like:\n",
    "- Speakers\n",
    "- Headphones\n",
    "- Microphones\n",
    "\n",
    "What AudioUtilities does:\n",
    "- Find Devices: It can list all the audio devices connected to your system.\n",
    "- Select Devices: You can choose a specific device to control (e.g., your default speakers or a specific microphone).\n",
    "- This acts as the entry point to locate the device you want to work with.\n",
    "\n",
    "2. IAudioEndpointVolume:\n",
    "This is the heart of controlling audio in pycaw. The IAudioEndpointVolume interface provides direct methods to manipulate the audio settings of an endpoint device. For example:\n",
    "- Set Volume: Change the device‚Äôs volume to a desired level.\n",
    "- Get Volume: Retrieve the current volume level.\n",
    "- Mute: Toggle mute functionality for the device.\n",
    "- Volume Range: It allows you to get details about the maximum and minimum volume levels supported by the device.\n",
    "\n",
    "How it works:\n",
    "- Your program needs to obtain an IAudioEndpointVolume object that corresponds to a specific audio device (e.g., your default speaker).\n",
    "- Once you have this object, you can call its methods to control the audio settings programmatically.\n",
    "\n",
    "How These Fit Together:\n",
    "- AudioUtilities helps you locate the audio endpoint (like your default speaker).\n",
    "- Once you find the desired endpoint, you use IAudioEndpointVolume to access and control its volume-related functionality.\n",
    "\n",
    "Example Scenario:\n",
    "Suppose you want to mute your speakers. You would:\n",
    "- Use AudioUtilities to find the default audio playback device.\n",
    "- Get the IAudioEndpointVolume object for that device.\n",
    "- Call the Mute() method to mute the device.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f78f3-6654-4051-85aa-ce4fe04a8d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MediaPipe)",
   "language": "python",
   "name": "mediapipe-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
