{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2929fece-8f2f-4d78-b273-8471c40dbf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Gesture Slide Controller...\n",
      "Make sure your presentation software is active!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui # Simulates keyboard presses for slide control\n",
    "import time # Used to implement cooldown timing.\n",
    "import numpy as np\n",
    "\n",
    "class GestureSlideController:\n",
    "    def __init__(self):\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(\n",
    "            max_num_hands=1,\n",
    "            min_detection_confidence=0.7,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        self.mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "        # Gesture parameters\n",
    "        self.prev_x = 0 # stores previous x-position of the hand (used to track motion)\n",
    "        self.action_cooldown = 0.1   # wait time between gestures to avoid accidental multiple triggers.\n",
    "        self.last_action_time = 0 # time of last detected gesture.\n",
    "        self.movement_threshold = 30   # minimum x-distance required to trigger a gesture.\n",
    "\n",
    "        # Smoothing\n",
    "        self.position_history = [] #Stores last few hand x-positions to smooth out noise\n",
    "        self.history_size = 5  \n",
    "\n",
    "        # UI elements\n",
    "        self.font = cv2.FONT_HERSHEY_SIMPLEX  #Font used to draw text instructions.\n",
    "\n",
    "    def smooth_position(self, current_x):\n",
    "        \"\"\"Apply smoothing to reduce jitter\"\"\"\n",
    "        self.position_history.append(current_x)\n",
    "        if len(self.position_history) > self.history_size:\n",
    "            self.position_history.pop(0)\n",
    "        return int(np.mean(self.position_history))  \n",
    "# Adds current x-position to position_history.\n",
    "#Maintains a sliding window of last 5 positions.\n",
    "#Returns the average of those values (smoother than just current_x).\n",
    "    def draw_ui(self, img):\n",
    "        \"\"\"Draw UI elements on the image\"\"\"\n",
    "        h, w, _ = img.shape\n",
    "\n",
    "        # Draw instructions\n",
    "        cv2.putText(img, \"Hand Gesture Slide Controller\", (10, 30), self.font, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(img, \"Move hand LEFT for next slide\", (10, 60), self.font, 0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(img, \"Move hand RIGHT for previous slide\", (10, 80), self.font, 0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(img, \"Press 'q' to quit\", (10, 100), self.font, 0.5, (255, 255, 255), 1)\n",
    "#Title, Instructions\n",
    "        # Draw center line\n",
    "        cv2.line(img, (w//2, 0), (w//2, h), (100, 100, 100), 1)\n",
    "\n",
    "        # Draw threshold zones\n",
    "        left_zone = w//2 - self.movement_threshold #left_zone and right_zone define gesture-triggering areas \n",
    "#(move across this threshold to trigger a slide change).\n",
    "        right_zone = w//2 + self.movement_threshold\n",
    "        cv2.line(img, (left_zone, 0), (left_zone, h), (0, 255, 255), 1)\n",
    "        cv2.line(img, (right_zone, 0), (right_zone, h), (0, 255, 255), 1)\n",
    "\n",
    "        # Show cooldown status\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_action_time < self.action_cooldown:\n",
    "            remaining = self.action_cooldown - (current_time - self.last_action_time) #Cooldown timer\n",
    "            cv2.putText(img, f\"Cooldown: {remaining:.1f}s\", (10, h-20), self.font, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    def process_gesture(self, lm_list): #Called when hand landmarks are detected.\n",
    "        \"\"\"Process hand landmarks for gesture recognition\"\"\"\n",
    "        current_time = time.time()\n",
    "\n",
    "        # If no hand is detected, reset tracking values\n",
    "        if not lm_list:\n",
    "            self.prev_x = 0  # Reset hand position tracking\n",
    "            self.last_action_time = 0  # Also reset action timing\n",
    "            return\n",
    "        \n",
    "        current_x = lm_list[9][0]  # Gets the x-coordinate of landmark 9 (index finger base or wrist-like point).\n",
    "\n",
    "        # If hand reappears after disappearance, take fresh position & wait briefly\n",
    "        if self.prev_x == 0:\n",
    "            self.prev_x = current_x  # Initialize fresh starting position\n",
    "            self.last_action_time = current_time  # Reset timer\n",
    "            return\n",
    "\n",
    "        # Ignore large jumps in movement when hand reappears (avoids false triggers)\n",
    "        if abs(current_x - self.prev_x) > 200:  # Adjust threshold if needed\n",
    "            self.prev_x = current_x  # Stabilize new hand position before detecting gestures\n",
    "            return\n",
    "\n",
    "        # Check cooldown period\n",
    "        if current_time - self.last_action_time <= self.action_cooldown:\n",
    "            return\n",
    "\n",
    "        # Calculate movement difference\n",
    "        diff = current_x - self.prev_x\n",
    "\n",
    "\n",
    "        if abs(diff) > self.movement_threshold:\n",
    "            if diff < -self.movement_threshold: #If hand moved left → next slide (right key)\n",
    "                print(f\"Next Slide (Hand moved LEFT by {abs(diff)} pixels)\")\n",
    "                pyautogui.press(\"right\")\n",
    "            elif diff > self.movement_threshold:   #If hand moved right → previous slide (left key)\n",
    "                print(f\"Previous Slide (Hand moved RIGHT by {diff} pixels)\")\n",
    "                pyautogui.press(\"left\")\n",
    "            #last_action_time updated after a gesture is performed.\n",
    "            # Update last action time\n",
    "            self.last_action_time = current_time\n",
    "        \n",
    "        # Update the previous position\n",
    "        self.prev_x = current_x\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main loop\"\"\"\n",
    "        print(\"Starting Gesture Slide Controller...\")\n",
    "        print(\"Make sure your presentation software is active!\")\n",
    "\n",
    "#Webcam frames are read\n",
    "\n",
    "#Hand detection is applied\n",
    "\n",
    "#UI and gesture logic are updated\n",
    "\n",
    "#Output window is shown\n",
    "        while True:\n",
    "            success, img = self.cap.read()\n",
    "            if not success:\n",
    "                print(\"Failed to read from camera\")\n",
    "                break\n",
    "            \n",
    "            img = cv2.flip(img, 1)  # Flip horizontally\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            results = self.hands.process(img_rgb)\n",
    "\n",
    "            # Draw UI elements\n",
    "            self.draw_ui(img)\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                for handLms in results.multi_hand_landmarks:\n",
    "                    self.mp_draw.draw_landmarks(img, handLms, self.mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    # Extract landmark positions\n",
    "                    lm_list = [(int(lm.x * img.shape[1]), int(lm.y * img.shape[0])) for lm in handLms.landmark]\n",
    "#Extracts (x, y) pixel positions of each landmark.\n",
    "\n",
    "#Calls process_gesture() to decide if movement indicates a slide change.\n",
    "\n",
    "#Highlights wrist point (landmark 9).\n",
    "                    # Process gestures\n",
    "                    self.process_gesture(lm_list)\n",
    "\n",
    "                    # Highlight wrist position\n",
    "                    if lm_list:\n",
    "                        wrist_pos = lm_list[9]\n",
    "                        cv2.circle(img, wrist_pos, 10, (255, 0, 0), -1)\n",
    "\n",
    "            cv2.imshow(\"Gesture Slide Controller\", img)\n",
    "\n",
    "            # Exit condition\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('r'):  # Reset position\n",
    "                self.prev_x = 0\n",
    "                self.position_history = []\n",
    "                print(\"Position reset\")\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up resources\"\"\"\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        #tops webcam and closes the OpenCV window.\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    controller = GestureSlideController()\n",
    "    try:\n",
    "        controller.run()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopping controller...\")\n",
    "    finally:\n",
    "        controller.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf52e14-cf2c-417f-9518-cd90c0343807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
